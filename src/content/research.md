### Examining Bias in LLM-Based Matchmaking
Role: Thesis Research
Location: OnCare Lab (Advisor: Professor Koustuv Saha)
Period: Aug 2025 - Present
Order: 1
Skills: LLMs, NLP, Fairness, Evaluation, Prompt Engineering, Computational Social Science, seaborn, pandas, numpy, scikit-learn
Links: [Lab Website](https://oncare.cs.illinois.edu)

- Social and personal decisions in relational domains such as matchmaking are deeply entwined with cultural norms and historical hierarchies, and can potentially be shaped by algorithmic and AI-mediated assessments of compatibility, acceptance, and stability. In South Asian contexts, caste remains a central aspect of marital decision-making, yet little is known about how contemporary large language models (LLMs) reproduce or disrupt caste-based stratification in such settings. We examined caste bias in LLM-mediated matchmaking evaluations using a controlled experimental design with real-world matrimonial profiles. 
- We varied caste identity across Brahmin, Kshatriya, Vaishya, Shudra, and Dalits, and income across five buckets, and evaluated five LLMs (GPT, Gemini, Llama, Qwen, and BharatGPT). Models were prompted to assess profiles along dimensions of social acceptance, marital stability, and cultural compatibility. 
- Our analysis reveals consistent hierarchical patterns across models: same-caste matches are rated most favorably, at an average 25% higher than inter-caste matches, which are ordered according to traditional caste hierarchy. 
- We further evaluated a guardrail-based prompting intervention designed to disrupt caste-referential reasoning. We find that although this approach substantially reduces hierarchical bias, it does not fully eliminate it. These findings highlight how existing caste hierarchies are replicated in LLM decision-making and the limits of prompt-level mitigation strategies. This work underscores the need for culturally grounded evaluation and intervention strategies in AI systems deployed in socially sensitive domains

### ALMA: Active Law-enforcement Mixed-strategy Allocator
Role: Graduate Researcher
Location: Advisor: Professor Ruta Mehta
Period: Aug 2025 - Present
Order: 2
Skills: Game Theory, Optimization, Python, Statistical Modeling
Links: [Paper](https://github.com/atharvanaik10/ALMA/blob/main/ALMA_paper.pdf)

- The Active Law-enforcement Mixed-strategy Allocator (ALMA) is a game-theoretic system to determine the optimal police patrol routes for the University of Illinois. The aim of this project is to use real-world data to explore possibilities to make our campus safer. Using a combination of existing Stackelberg Security Games (SSG) research and information from the police department, we uniquely create a program that creates patrol schedules that outperform random simulations.

### Uniform Distribution and Rigidity of Sequences
Role: Mathematics Research Assistant
Location: Illinois Mathematics Lab (Advisor: Professor Emeritus Joseph Rosenblatt)
Period: Jan 2023 - May 2023
Order: 3
Skills: Python, Data Visualization, Pure Math
Links: [Poster](https://uofi.app.box.com/s/i86r7bed0ll3jwgecqhlarzwwvccpjn5)

- There are a variety of interested questions concerning the uniform distribution and rigidity of sequences in the interval [0, 1]. These topics have been studied for many decades, but there still remain challenging open problems. Using theoretical methods and computational tools, we created a novel algorithm that quantifies the probability that a sequence will be uniformly distributed by an analysis of the distributions of its fractional parts.